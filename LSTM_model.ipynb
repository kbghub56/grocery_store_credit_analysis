{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kbghub56/grocery_store_credit_analysis/blob/main/LSTM_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5nqTctvDKP2",
        "outputId": "037aa1f6-c0f9-4f56-e48d-2e77290eb999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from google.colab import drive\n",
        "from sklearn.impute import SimpleImputer\n",
        "drive.mount('/content/drive') # Needed to access files in drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3FDG7fUDe1c"
      },
      "outputs": [],
      "source": [
        "y_data = pd.read_csv('/content/drive/My Drive/LSTM_analysis/231109_data_cohort3_inclnorcc_y.csv')\n",
        "x_data = pd.read_csv('/content/drive/My Drive/LSTM_analysis/231109_data_cohort3_inclnorcc_x.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CAta-0PE-8w"
      },
      "outputs": [],
      "source": [
        "# Convert transaction_date to datetime\n",
        "x_data['transaction_date'] = pd.to_datetime(x_data['transaction_date'])\n",
        "\n",
        "# Sort by person_id and transaction_date\n",
        "x_data.sort_values(by=['person_id', 'transaction_date'], inplace=True)\n",
        "\n",
        "\n",
        "print(x_data.head)\n",
        "\n",
        "# Normalize selected numeric features\n",
        "scaler = MinMaxScaler()\n",
        "numeric_columns = ['product_item_price_amount', 'product_item_gross_amount']  # Only these two features\n",
        "x_data[numeric_columns] = scaler.fit_transform(x_data[numeric_columns]) #Scales features based on min/max\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gXofnyT9MxN"
      },
      "outputs": [],
      "source": [
        "# Create sequences\n",
        "time_steps = 10  # Modify as needed\n",
        "\n",
        "# Initialize an empty list to store the sequences\n",
        "sequences = []\n",
        "\n",
        "# Group the DataFrame by 'person_id'\n",
        "grouped_data = x_data.groupby('person_id')\n",
        "\n",
        "# Iterate over each group in the grouped data\n",
        "for person_id, group in grouped_data:\n",
        "    # Select only the columns specified in numeric_columns\n",
        "    numeric_data = group[numeric_columns]\n",
        "\n",
        "    # Convert the selected data to a NumPy array\n",
        "    numeric_array = numeric_data.values\n",
        "\n",
        "    # Append the NumPy array to the list of sequences\n",
        "    sequences.append(numeric_array)\n",
        "\n",
        "#Pad sequences to ensure equal length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=time_steps, padding='post', dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0nrmp5r-CdT"
      },
      "outputs": [],
      "source": [
        "lstm_input = np.array(padded_sequences)\n",
        "lstm_input = lstm_input.reshape((lstm_input.shape[0], time_steps, -1)) #Reshaping into 3D array, seq, time step, features\n",
        "print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9498oSqP-D04"
      },
      "outputs": [],
      "source": [
        "# Align y_data with X data\n",
        "y_aligned = y_data.set_index('person_id').loc[x_data['person_id'].unique()].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ClCIDQH-HuR"
      },
      "outputs": [],
      "source": [
        "# Define the LSTM model\n",
        "def create_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(LSTM(50))\n",
        "    model.add(Dense(1, activation='sigmoid'))#Output layer # modify this to return score\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC()])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n13xvDLL-NEV",
        "outputId": "8e772cbf-255d-4973-a0a9-fe9de7a58d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "805/805 [==============================] - 19s 18ms/step - loss: 0.6932 - auc: 0.5017\n",
            "Epoch 2/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6930 - auc: 0.5078\n",
            "Epoch 3/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6927 - auc: 0.5140\n",
            "Epoch 4/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6913 - auc: 0.5321\n",
            "Epoch 5/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6898 - auc: 0.5435\n",
            "Epoch 6/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6881 - auc: 0.5538\n",
            "Epoch 7/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6872 - auc: 0.5568\n",
            "Epoch 8/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6868 - auc: 0.5599\n",
            "Epoch 9/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6862 - auc: 0.5609\n",
            "Epoch 10/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6854 - auc: 0.5630\n",
            "Epoch 1/10\n",
            "805/805 [==============================] - 18s 16ms/step - loss: 0.6932 - auc_1: 0.5018\n",
            "Epoch 2/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6928 - auc_1: 0.5103\n",
            "Epoch 3/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6919 - auc_1: 0.5262\n",
            "Epoch 4/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6908 - auc_1: 0.5359\n",
            "Epoch 5/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6898 - auc_1: 0.5437\n",
            "Epoch 6/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6882 - auc_1: 0.5519\n",
            "Epoch 7/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6867 - auc_1: 0.5597\n",
            "Epoch 8/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6861 - auc_1: 0.5609\n",
            "Epoch 9/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6854 - auc_1: 0.5639\n",
            "Epoch 10/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6845 - auc_1: 0.5681\n",
            "Epoch 1/10\n",
            "805/805 [==============================] - 19s 18ms/step - loss: 0.6932 - auc_2: 0.5012\n",
            "Epoch 2/10\n",
            "805/805 [==============================] - 14s 17ms/step - loss: 0.6927 - auc_2: 0.5132\n",
            "Epoch 3/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6914 - auc_2: 0.5297\n",
            "Epoch 4/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6892 - auc_2: 0.5477\n",
            "Epoch 5/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6881 - auc_2: 0.5532\n",
            "Epoch 6/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6869 - auc_2: 0.5599\n",
            "Epoch 7/10\n",
            "805/805 [==============================] - 13s 17ms/step - loss: 0.6860 - auc_2: 0.5613\n",
            "Epoch 8/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6856 - auc_2: 0.5629\n",
            "Epoch 9/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6849 - auc_2: 0.5657\n",
            "Epoch 10/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6843 - auc_2: 0.5668\n",
            "Epoch 1/10\n",
            "805/805 [==============================] - 19s 16ms/step - loss: 0.6932 - auc_3: 0.4978\n",
            "Epoch 2/10\n",
            "805/805 [==============================] - 14s 17ms/step - loss: 0.6930 - auc_3: 0.5054\n",
            "Epoch 3/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6927 - auc_3: 0.5141\n",
            "Epoch 4/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6916 - auc_3: 0.5271\n",
            "Epoch 5/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6906 - auc_3: 0.5357\n",
            "Epoch 6/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6893 - auc_3: 0.5453\n",
            "Epoch 7/10\n",
            "805/805 [==============================] - 14s 17ms/step - loss: 0.6886 - auc_3: 0.5505\n",
            "Epoch 8/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6880 - auc_3: 0.5524\n",
            "Epoch 9/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6871 - auc_3: 0.5562\n",
            "Epoch 10/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6864 - auc_3: 0.5578\n",
            "Epoch 1/10\n",
            "805/805 [==============================] - 19s 18ms/step - loss: 0.6933 - auc_4: 0.4962\n",
            "Epoch 2/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6928 - auc_4: 0.5135\n",
            "Epoch 3/10\n",
            "805/805 [==============================] - 13s 17ms/step - loss: 0.6915 - auc_4: 0.5300\n",
            "Epoch 4/10\n",
            "805/805 [==============================] - 12s 15ms/step - loss: 0.6896 - auc_4: 0.5430\n",
            "Epoch 5/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6876 - auc_4: 0.5557\n",
            "Epoch 6/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6865 - auc_4: 0.5600\n",
            "Epoch 7/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6853 - auc_4: 0.5652\n",
            "Epoch 8/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6840 - auc_4: 0.5681\n",
            "Epoch 9/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6834 - auc_4: 0.5712\n",
            "Epoch 10/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6833 - auc_4: 0.5711\n",
            "Epoch 1/10\n",
            "805/805 [==============================] - 19s 16ms/step - loss: 0.6932 - auc_5: 0.5040\n",
            "Epoch 2/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6927 - auc_5: 0.5120\n",
            "Epoch 3/10\n",
            "805/805 [==============================] - 15s 18ms/step - loss: 0.6910 - auc_5: 0.5355\n",
            "Epoch 4/10\n",
            "805/805 [==============================] - 15s 18ms/step - loss: 0.6897 - auc_5: 0.5448\n",
            "Epoch 5/10\n",
            "805/805 [==============================] - 14s 17ms/step - loss: 0.6876 - auc_5: 0.5554\n",
            "Epoch 6/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6869 - auc_5: 0.5581\n",
            "Epoch 7/10\n",
            "805/805 [==============================] - 21s 26ms/step - loss: 0.6861 - auc_5: 0.5613\n",
            "Epoch 8/10\n",
            "805/805 [==============================] - 14s 17ms/step - loss: 0.6856 - auc_5: 0.5644\n",
            "Epoch 9/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6838 - auc_5: 0.5706\n",
            "Epoch 10/10\n",
            "805/805 [==============================] - 15s 18ms/step - loss: 0.6832 - auc_5: 0.5709\n",
            "Epoch 1/10\n",
            "805/805 [==============================] - 18s 18ms/step - loss: 0.6932 - auc_6: 0.5003\n",
            "Epoch 2/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6928 - auc_6: 0.5139\n",
            "Epoch 3/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6919 - auc_6: 0.5271\n",
            "Epoch 4/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6910 - auc_6: 0.5349\n",
            "Epoch 5/10\n",
            "805/805 [==============================] - 13s 17ms/step - loss: 0.6891 - auc_6: 0.5479\n",
            "Epoch 6/10\n",
            "805/805 [==============================] - 15s 18ms/step - loss: 0.6882 - auc_6: 0.5520\n",
            "Epoch 7/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6870 - auc_6: 0.5576\n",
            "Epoch 8/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6864 - auc_6: 0.5600\n",
            "Epoch 9/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6855 - auc_6: 0.5624\n",
            "Epoch 10/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6854 - auc_6: 0.5638\n",
            "Epoch 1/10\n",
            "805/805 [==============================] - 19s 18ms/step - loss: 0.6932 - auc_7: 0.5037\n",
            "Epoch 2/10\n",
            "805/805 [==============================] - 14s 17ms/step - loss: 0.6930 - auc_7: 0.5070\n",
            "Epoch 3/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6923 - auc_7: 0.5210\n",
            "Epoch 4/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6912 - auc_7: 0.5313\n",
            "Epoch 5/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6892 - auc_7: 0.5475\n",
            "Epoch 6/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6880 - auc_7: 0.5540\n",
            "Epoch 7/10\n",
            "805/805 [==============================] - 14s 17ms/step - loss: 0.6874 - auc_7: 0.5564\n",
            "Epoch 8/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6866 - auc_7: 0.5606\n",
            "Epoch 9/10\n",
            "805/805 [==============================] - 14s 17ms/step - loss: 0.6863 - auc_7: 0.5607\n",
            "Epoch 10/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6861 - auc_7: 0.5626\n",
            "Epoch 1/10\n",
            "805/805 [==============================] - 19s 16ms/step - loss: 0.6932 - auc_8: 0.5001\n",
            "Epoch 2/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6931 - auc_8: 0.5068\n",
            "Epoch 3/10\n",
            "805/805 [==============================] - 15s 18ms/step - loss: 0.6923 - auc_8: 0.5218\n",
            "Epoch 4/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6912 - auc_8: 0.5320\n",
            "Epoch 5/10\n",
            "805/805 [==============================] - 14s 17ms/step - loss: 0.6892 - auc_8: 0.5471\n",
            "Epoch 6/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6876 - auc_8: 0.5566\n",
            "Epoch 7/10\n",
            "805/805 [==============================] - 14s 17ms/step - loss: 0.6868 - auc_8: 0.5601\n",
            "Epoch 8/10\n",
            "805/805 [==============================] - 15s 18ms/step - loss: 0.6859 - auc_8: 0.5630\n",
            "Epoch 9/10\n",
            "805/805 [==============================] - 15s 18ms/step - loss: 0.6852 - auc_8: 0.5651\n",
            "Epoch 10/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6849 - auc_8: 0.5648\n",
            "Epoch 1/10\n",
            "805/805 [==============================] - 18s 18ms/step - loss: 0.6932 - auc_9: 0.4964\n",
            "Epoch 2/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6930 - auc_9: 0.5071\n",
            "Epoch 3/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6918 - auc_9: 0.5261\n",
            "Epoch 4/10\n",
            "805/805 [==============================] - 13s 17ms/step - loss: 0.6900 - auc_9: 0.5431\n",
            "Epoch 5/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6877 - auc_9: 0.5557\n",
            "Epoch 6/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6867 - auc_9: 0.5600\n",
            "Epoch 7/10\n",
            "805/805 [==============================] - 15s 18ms/step - loss: 0.6859 - auc_9: 0.5629\n",
            "Epoch 8/10\n",
            "805/805 [==============================] - 13s 16ms/step - loss: 0.6846 - auc_9: 0.5675\n",
            "Epoch 9/10\n",
            "805/805 [==============================] - 13s 17ms/step - loss: 0.6847 - auc_9: 0.5656\n",
            "Epoch 10/10\n",
            "805/805 [==============================] - 14s 18ms/step - loss: 0.6842 - auc_9: 0.5675\n"
          ]
        }
      ],
      "source": [
        "# 10-Fold Cross-Validation\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "auc_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(lstm_input, y_aligned):\n",
        "    X_train, X_test = lstm_input[train_index], lstm_input[test_index]\n",
        "    y_train, y_test = y_aligned[train_index], y_aligned[test_index]\n",
        "\n",
        "    # Flatten, impute, and apply SMOTE to training data\n",
        "    X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    X_train_flat = imputer.fit_transform(X_train_flat)\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train_flat, y_train.ravel())\n",
        "    X_train_smote = X_train_smote.reshape((-1, time_steps, X_train.shape[2]))\n",
        "\n",
        "    # Create and train the model, training new model for each fold to evaluate preformance\n",
        "    model = create_model((time_steps, X_train.shape[2]))\n",
        "    model.fit(X_train_smote, y_train_smote, epochs=10, batch_size=64)\n",
        "\n",
        "    # Evaluate the model\n",
        "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "    auc_scores.append(scores[1])  # Assuming AUC is the second metric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "auc_scores = []\n",
        "\n",
        "X_train, X_test = lstm_input[1], lstm_input[1]\n",
        "y_train, y_test = y_aligned[1], y_aligned[1]\n",
        "\n",
        "    # Flatten, impute, and apply SMOTE to training data\n",
        "    X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    X_train_flat = imputer.fit_transform(X_train_flat)\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train_flat, y_train.ravel())\n",
        "    X_train_smote = X_train_smote.reshape((-1, time_steps, X_train.shape[2]))\n",
        "\n",
        "    # Create and train the model, training new model for each fold to evaluate preformance\n",
        "    model = create_model((time_steps, X_train.shape[2]))\n",
        "    model.fit(X_train_smote, y_train_smote, epochs=10, batch_size=64)\n",
        "\n",
        "    # Evaluate the model\n",
        "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "    auc_scores.append(scores[1])  # Assuming AUC is the second metric"
      ],
      "metadata": {
        "id": "NOGAzx0lyY1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3CpefLvcMiX",
        "outputId": "007a057f-8215-429b-c647-7f2ed37b05f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average AUC Score: 0.5527050971984864\n"
          ]
        }
      ],
      "source": [
        "# Calculate average AUC score\n",
        "average_auc = np.mean(auc_scores)\n",
        "print(f\"Average AUC Score: {average_auc}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}